{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Helper_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (validation_images, validation_labels) = tf.keras.datasets.mnist.load_data()\n",
    "#train_images = np.expand_dims(train_images, axis = 3)\n",
    "#validation_images = np.expand_dims(validation_images, axis = 3)\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60k 28x28 train images with labels  \n",
    "10k 28x28 validation images with labels  \n",
    "now build the mnist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_set_statistics(images: np.ndarray, labels: np.ndarray, mu, rho):\n",
    "    #check tensor dimensions\n",
    "    if images.shape[0] != labels.shape[0]:\n",
    "        raise IndexError\n",
    "    array_dict = dict()\n",
    "    #set majority class size to the minimal avaliable class size\n",
    "    majority_size = np.min(np.unique(labels, return_counts=True)[1])\n",
    "    #extract every class from the images array, make it an array, shuffle it, \n",
    "    #and shorten in length such that len(every class) == majority_size\n",
    "    for i in np.unique(labels):\n",
    "        array_dict[i] = train_images[np.where(train_labels == i)]\n",
    "        np.random.shuffle(array_dict[i])\n",
    "        array_dict[i] = array_dict[i][:majority_size]\n",
    "    #set minority class size\n",
    "    minority_size = int(np.round(majority_size / rho))\n",
    "    #if step imbalance variant chosen\n",
    "    if mu is not None:\n",
    "        #set numbers of minority and majroity classes\n",
    "        minority_no = int(np.round(mu * len(array_dict)))\n",
    "        majority_no = len(array_dict) - minority_no\n",
    "        #create list of unique shuffled labels\n",
    "        list_of_labels = np.unique(labels)\n",
    "        np.random.shuffle(list_of_labels)\n",
    "        #init output np arrays\n",
    "        out_labels = np.empty(shape = tuple(labels.shape[i] if i != 0\n",
    "                                            else 0\n",
    "                                            for i in range(len(labels.shape))))\n",
    "        out_images = np.empty(shape = tuple(images.shape[i] if i != 0 \n",
    "                                            else 0\n",
    "                                            for i in range(len(images.shape))))\n",
    "        #add minority classes to concatenaded output tensors\n",
    "        for i in range(minority_no):\n",
    "            array_dict[list_of_labels[i]] = array_dict[list_of_labels[i]][:minority_size]\n",
    "            tmp_labels = np.full(shape = tuple(labels.shape[i] if i != 0\n",
    "                                            else minority_size\n",
    "                                            for i in range(len(labels.shape))), \n",
    "                                 fill_value = list_of_labels[i])\n",
    "            out_images = np.concatenate((out_images, array_dict[list_of_labels[i]]))\n",
    "            out_labels = np.concatenate((out_labels, tmp_labels))\n",
    "        for i in range(minority_no, len(array_dict), 1):\n",
    "            tmp_labels = np.full(shape = tuple(labels.shape[i] if i != 0\n",
    "                                            else majority_size\n",
    "                                            for i in range(len(labels.shape))), \n",
    "                                 fill_value = list_of_labels[i])\n",
    "            out_images = np.concatenate((out_images, array_dict[list_of_labels[i]]))\n",
    "            out_labels = np.concatenate((out_labels, tmp_labels))\n",
    "        return (out_images, out_labels)\n",
    "    #todo: mu is None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 2710, 1.0: 5421, 2.0: 5421, 3.0: 5421, 4.0: 5421, 5.0: 5421, 6.0: 5421, 7.0: 2710, 8.0: 5421, 9.0: 5421}\n"
     ]
    }
   ],
   "source": [
    "(obrazki, naklejki) = change_set_statistics(train_images, train_labels, 0.2, 2)\n",
    "print(hf.Imbalance.get_set_distribution(naklejki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "zeros = train_images[np.where(train_labels == 0)]\n",
    "print(len(train_labels.shape))\n",
    "print(tuple(train_labels.shape[i] for i in range(len(train_labels.shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "print(hf.Imbalance.get_set_distribution(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3f63f687c8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                             \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             for i in range(len(train_labels.shape))))\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "out_labels = np.empty(shape = tuple(train_labels.shape[i] if i != 0\n",
    "                                            else 0\n",
    "                                            for i in range(len(train_labels.shape))))\n",
    "np.concatenate(out_labels, np.full(shape = 100, fill_value = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
